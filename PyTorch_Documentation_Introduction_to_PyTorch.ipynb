{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj0REAZCP2KEUqu4J0ROqq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BedinEduardo/Colab_Repositories/blob/master/PyTorch_Documentation_Introduction_to_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to PyTorch - YouTube Series\n",
        "\n",
        "## Running the Tutorial Code\n",
        "\n",
        "* **On the Cloud**:\n",
        "* **Locally**:\n",
        "\n",
        "## Introduction to PyTorch\n",
        "\n",
        "Follow along with the video below or on [YouTube](https://www.youtube.com/watch?v=IC0_FRiX-sw)\n",
        "\n",
        "* What is **PyTorch**: An open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
        "* **Machine Learning Framework**:\n",
        "  * DL primitives, NN layers types, activation and loss functions, optimizers\n",
        "  * **Research Prototyping**:\n",
        "    * Models are Python code, Autograd and \"eager mode\" for dynamic model architectures\n",
        "  * **Product Deployment**:\n",
        "    * TorchScript, TorchServe, quantization\n",
        "  * **Open Source**\n",
        "\n",
        "### Tensors\n",
        "\n",
        "### Autograd\n",
        "\n",
        "**Automatic Differentiation Engine**: Computation as a *graph buiilt at run time*\n",
        "\n",
        "Gradient w.r.t the input Tensors is computed step-by-step from **loss** to top reverse.\n",
        "\n",
        "### Building Models in PyTorch\n",
        "\n",
        "### Datasets and DataLoaders\n",
        "\n",
        "Datasets get the data, standard or own dataset, and DataLoader is an 'organizer' of the data.\n",
        "\n",
        "### Training Your PyTorch Model\n",
        "\n",
        "### Deployment With TorchScript\n",
        "\n",
        "Connect to a system to connect the model to the world.\n",
        "\n",
        "**TorchScript**: A static, High-Performance subset of Python\n",
        "1. Prototype your model with PyTorch\n",
        "2. Control flow is preserved\n",
        "3. First-class support for lists, dicts, etc.\n",
        "\n",
        "**PyTorch JIT**: An optmizing just-in-time compiler for PyTorch programs\n",
        "1. Lightweight, thread-safe interpreter\n",
        "2. Easy to write custom transformations\n",
        "3. Not just for inference! Autodiff support.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0jL4SYzlJsDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Tensors"
      ],
      "metadata": {
        "id": "dGGax2osZU3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "Xi4zzLDtZYLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see a few basic tensor multiplications. First, just a few of the ways to build tensors"
      ],
      "metadata": {
        "id": "qH4JWMSaZZ7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.zeros(5,3)\n",
        "print(z)\n",
        "print(z.dtype)"
      ],
      "metadata": {
        "id": "QDIkiKbpZjig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb8f7a9-31ee-4425-c0ef-1abcd89241f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The defualt of PyTorhc is build a 32-bit floating point numbers"
      ],
      "metadata": {
        "id": "wNd7l3LpZsqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = torch.ones((5,3), dtype=torch.int16)\n",
        "print(i)"
      ],
      "metadata": {
        "id": "V5CLtsgAZ0qm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b95cb792-f9e3-4022-b8e8-092acb8d9bd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]], dtype=torch.int16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is common to initialize learning weights randomly, often with a specific seed fot the PRNG for reproducibility of results."
      ],
      "metadata": {
        "id": "9qFUknn_aAFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1311)\n",
        "r1 = torch.rand(2,2)\n",
        "print(\"Random tensor \\n\")\n",
        "print(r1)"
      ],
      "metadata": {
        "id": "dnQMokssaPWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb0c458c-4a47-49fb-8450-22deb2ccde73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random tensor \n",
            "\n",
            "tensor([[0.3833, 0.0483],\n",
            "        [0.3644, 0.8854]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = torch.rand(2,2)\n",
        "\n",
        "print(r2)"
      ],
      "metadata": {
        "id": "EsN10whsablh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5423455-0fbd-4543-c7c6-98746974c359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0847, 0.5025],\n",
            "        [0.7393, 0.8959]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1311)\n",
        "r3 = torch.rand(2,2)\n",
        "\n",
        "print(r3)"
      ],
      "metadata": {
        "id": "CrgB-lEQaj2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d1bda84-c7fb-4b83-cbb7-ca629d716d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3833, 0.0483],\n",
            "        [0.3644, 0.8854]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch tensors perform arithmetic operations intuitively. Tensors of similar shapes may be added, multiplied, etc. Operations with scalars are distributed over the tensor:"
      ],
      "metadata": {
        "id": "jWIdzdTLarE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(2,3)\n",
        "print(ones)"
      ],
      "metadata": {
        "id": "gEPKqSoYbHzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "812f0563-c930-4eb8-a258-4f3819b8f24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twos = torch.ones(2,3)\n",
        "print(twos)"
      ],
      "metadata": {
        "id": "NuHXMQL0bMTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16f78b5-da69-4e3b-b2d4-cdda7416484b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threes = ones + twos\n",
        "print(threes)\n",
        "print(threes.shape)"
      ],
      "metadata": {
        "id": "MZSbmY5RbSKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df90534a-e673-4401-f698-9ef8c2c382f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.]])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = torch.rand(2,3)\n",
        "r2 = torch.rand(3,2)\n",
        "\n",
        "r3 = r1 + r2.T\n",
        "print(r3)"
      ],
      "metadata": {
        "id": "b6YPXgePbatx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bfdd8e7-1d9a-4efc-fb06-f3b0b82dab42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3563, 1.1770, 1.7332],\n",
            "        [1.7644, 1.3273, 0.5693]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a small smaple of the mathematical operations available:"
      ],
      "metadata": {
        "id": "de3yMr6TbpqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = (torch.rand(2,2)-0.5)*2\n",
        "print(r)"
      ],
      "metadata": {
        "id": "jTZEZkRKb2Rm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167cb3f2-6c90-4e41-d898-a71da3cfde83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0315, -0.3269],\n",
            "        [ 0.2884, -0.0202]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Absolute value of r:\")\n",
        "print(torch.abs(r))   #turn all values in positive values"
      ],
      "metadata": {
        "id": "7hHVhClwbXd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3732af66-05cc-4dc5-99c2-1f25acad3a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Absolute value of r:\n",
            "tensor([[0.0315, 0.3269],\n",
            "        [0.2884, 0.0202]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trigonometric functions\n",
        "print(\"\\n Inverse sine of r: \")\n",
        "print(torch.asin(r))"
      ],
      "metadata": {
        "id": "LjWWKNSrcLVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2e9b5df-3ff9-4e96-d30f-6f72cf51e076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Inverse sine of r: \n",
            "tensor([[ 0.0315, -0.3330],\n",
            "        [ 0.2925, -0.0202]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... and linear algebra operations like determinant and singular value decomposition\n",
        "print('\\nDeterminant of r: ')\n",
        "print(torch.det(r))\n",
        "print(\"\\nSingular value decomposition of r: \")\n",
        "print(torch.svd(r))\n"
      ],
      "metadata": {
        "id": "6xffQ_OBhq0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862f6de1-c215-44d4-a1d1-af42f1c0fdf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Determinant of r: \n",
            "tensor(0.0936)\n",
            "\n",
            "Singular value decomposition of r: \n",
            "torch.return_types.svd(\n",
            "U=tensor([[-0.8978, -0.4403],\n",
            "        [-0.4403,  0.8978]]),\n",
            "S=tensor([0.3399, 0.2754]),\n",
            "V=tensor([[-0.4566,  0.8897],\n",
            "        [ 0.8897,  0.4566]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... and statistical and aggregate operations\n",
        "print(\"\\n Average and standard deviation of r\")\n",
        "print(torch.std_mean(r))\n",
        "print(\"\\nMaximum value of r: \")\n",
        "print(torch.max(r))"
      ],
      "metadata": {
        "id": "RV8IhO19iD4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22455559-93ab-4fc1-95fc-6310dda365b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Average and standard deviation of r\n",
            "(tensor(0.2525), tensor(-0.0068))\n",
            "\n",
            "Maximum value of r: \n",
            "tensor(0.2884)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch Models"
      ],
      "metadata": {
        "id": "pBEVD0VpjPah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # for all things in PyTorch\n",
        "import torch.nn as nn    # For torch.nn.Module, the parent object for PyTorch models\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "tshNGgp9jVAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![LeNet.png](https://pytorch.org/tutorials/_images/mnist.png)\n",
        "\n",
        "Here is the abridged version of how ot works:\n",
        "\n",
        "* Layer C1 is a convolutional Layer, meaning that it scans the input for features it learned during training. It outputs a map of where it saw each of its learned features in the image. This \"activation map\" is downsampled in layer S2.\n",
        "* Layer C3 is another Convolutional layers, this time scanning C1's activation map for combinations of features. It also puts out in activation map describing the spatial locations of these features combinations, which is downsampled in layere S4.\n",
        "* Finally, the fully-connected layers at the end, F5, F6, and OUTPUT, are a classifier that takes the final activation map, and classifies it into one of ten bins representing 10 digits.\n",
        "\n",
        "How to express thrugh code this simple NN?"
      ],
      "metadata": {
        "id": "bm2zItlHj97G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeNet,self).__init__()\n",
        "    # 1 input image channel - brack and white - 6 output channel, 5x5 square convolution kernel\n",
        "    self.conv1 = nn.Conv2d(1,6,5)\n",
        "    self.conv2 = nn.Conv2d(6,16,5)\n",
        "    # an afine operation: y = Wx + b\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 form image dimension\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Max pooling over a (2,2) windown\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))  #if the size is a square you can only specify a single number\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def num_flat_features(self, x):\n",
        "    size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "    num_features = 1\n",
        "    for s in size:\n",
        "      num_features *= s\n",
        "\n",
        "    return num_features"
      ],
      "metadata": {
        "id": "e7N5ybAYnKSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking over this code, you should be able to spot some structural similarities with the diagram above.\n",
        "\n",
        "This demostrate the structure of a typical PyTorch model:\n",
        "\n",
        "* It inherits from `torch.nn.Module` - modules may be nested - in fact, even the `Conv2d` and `Linear` layer classes inherit from `torch.nn.Module`.\n",
        "* A model will have an `__init__()` function, where it instantiates its layers, and loads any data artifacts it might need\n",
        "* A model will have `forward()` function. This is where the actual computation happens: An input is passed through the network layer and various functions to generate an output.\n",
        "* Other than that, you can build out your model class like any other Python class,  adding whatever properties and methods you need to support your's models computation.\n",
        "\n",
        "Lets instantiate this object and run a sample input through it.\n"
      ],
      "metadata": {
        "id": "1FZzGSHswju7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = LeNet()\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "id": "t_Cj6hUsyTml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74066c4c-6154-431f-b85a-86cd16adf059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.rand(1,1,32,32)\n",
        "print(\"\\nImage batch shape: \")\n",
        "print(input.shape)"
      ],
      "metadata": {
        "id": "cF1ABJ2qy4rJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a188b26-ccbf-4141-965e-7505a6794502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image batch shape: \n",
            "torch.Size([1, 1, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = net(input)\n",
        "print(\"\\nRaw output\")\n",
        "print(output)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "51oCoGihzoFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed044aec-36a3-4cab-b93b-0eab885eb1a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raw output\n",
            "tensor([[-0.0215, -0.0488, -0.0732, -0.0536,  0.0191,  0.0488,  0.0884,  0.0356,\n",
            "          0.0182,  0.1429]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Instantiate `LeNet` class, -> print the `net`. Subclass of `torch.nn.Module` will report the layers it has builded and their shapes and parameters. - Overview of the model.\n",
        "\n",
        "2. Build a dummy imput of 32x32 image with 1 channel color. Load the image and convert it to a tensor.\n",
        "\n",
        "3. *batch_dimension* - PyTorch Models assume they are working on *batches* of data - for examples, a batch of 16 of our image tiles would have a shape `(16,1,32,32).\n",
        "\n",
        "4. Calling the function `net(input)`. Models confidence. Looking the `output`, can see that it also has a batch dimension, the size of which should alwayes match the input batch dimension."
      ],
      "metadata": {
        "id": "GXMNAMX50ku2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets and DataLoaders\n",
        "\n",
        "We are going to demostrate using one of the ready-to-download, open-access datasets from TorchVision, how to transform the images for consuption by your model, and how to use the DataLoader to feed batches of data toy your model."
      ],
      "metadata": {
        "id": "r2fmQ0Xt2Qy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform the incoming image into a tensor\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), # tensor transformation\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))]  # Check this values where they come from\n",
        ")"
      ],
      "metadata": {
        "id": "iCBmROlZ3KGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `transforms.ToTensor()` converts images loaded by Pillow into PyTorch Tensors\n",
        "* `transforms.Normalize()` adjust the values of the tensor so that their average is zero and their standard deviation is 1.0. Most activation function have their strongest gradient descent around x=0 - speed learning. The values passed to the transform are the means (1st tuple) and the standard deviation (2nd touple) of the RGB values of the image in the dataset.\n",
        "\n",
        "Now build an instance of the CIFAR10 dataset - this is a set of 32x32 color image tiles representing 10 classes of objects."
      ],
      "metadata": {
        "id": "Y8ULHoCx4G2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                         train=True,\n",
        "                                         download=True,\n",
        "                                         transform=transform)"
      ],
      "metadata": {
        "id": "t8z3mDyn49Rv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc926b0c-f675-44ab-c8c7-5fa1b1bd61fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 42.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Donwloadable datasets are subclasses od `torch.utils.data.Dataset`. `Dataset` classes in PyTorch include the downloaded datasets, Video, audio, and text. As weel as utility dataaset classes such as `torchvision.datasets.ImageFolder`, which will read a folder of labeled images. You can also build your own subclasses of `Dataset`.\n",
        "\n",
        "When we instantiate our dataset:\n",
        "* The filesystem path to where we want the data to do.\n",
        "* Whether or not we are using this set for training: most datasets will be split into training and test subsets.\n",
        "* Wheter we would like to download the dataset if we have not already.\n",
        "* The transformations we want to apply to the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "qlI7F1-l-u73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traindataloader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "EVJVKKtCAfhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `DataLoader` knows *nothing** about the data, but organizes the input tensors served by the `Dataset` into batches with the parameters that you specify.\n",
        "\n",
        "`shufle=True` - randomize the data order"
      ],
      "metadata": {
        "id": "sv9OhG75ArHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "classes = ('plane', 'car', 'bird','cat','deer','dog','frog','horse','ship','truck')\n",
        "\n",
        "def imshow(img):\n",
        "  img = img / 2 + 0.5\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg,(1,2,0)))"
      ],
      "metadata": {
        "id": "OvTv7vvsBj9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get some random training images\n",
        "dataiter = iter(traindataloader)\n",
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "id": "OYL-0qyxCDVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "#labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "id": "7OvIzFTQCMk3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "c7ee9da0-a36f-4638-c0a2-23de09d46731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-0.45793372..1.5632443].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "truck   cat horse plane\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training you PyTorch Model"
      ],
      "metadata": {
        "id": "-N4MLIy3hB5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F   # https://pytorch.org/docs/stable/nn.functional.html#torch-nn-functional\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "t0NefRcJhKTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First it is needed to training test datasets. if you have not already, run the cell below to make sure the dataset is downloaded\n"
      ],
      "metadata": {
        "id": "rtd7DRWehqqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n",
        ")\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "traindataloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                         shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "tesdataloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                            shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
      ],
      "metadata": {
        "id": "yddHcXtah60C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the output from `DataLoader`"
      ],
      "metadata": {
        "id": "Ub_NKlyPjg6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "  img = img / 2 + 0.5   # unnormalize\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1,2,0)))\n",
        "\n",
        "# get some random training imges\n",
        "dataiter = iter(traindataloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "metadata": {
        "id": "JQRSljnuk-RM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "e31329d8-eaf0-4f2e-fad4-9840cf8ad20f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " deer  deer truck   dog\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The model to train, it is a variant of LeNet - discussed earlier - adapted for 3-color images\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,6,5)  # nn.Conv2d(in_channels, out_channles, kernel_size, stride=1, padding=0, dilatation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
        "    self.pool = nn.MaxPool2d(2,2)  # nn.MaxPool2d(kernel_size,stride=None,padding=0,dilation=1, return_indice=False, ceil_mode=False)  Applies a 2D maxpooling over an input signal composed of several input planes\n",
        "    self.conv2 = nn.Conv2d(6,16,5) # Applies a 2D convolution over an input signal composed of several inputn planes\n",
        "    self.fc1 = nn.Linear(16 * 5 *5, 120)  # Applies an affine linear transformation to the incoming data -- nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
        "    self.fc2 = nn.Linear(120,84)\n",
        "    self.fc3 = nn.Linear(84,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))  # get the conv1 -> execute the convolution, this output pass trough a ReLU activation, and the output of ReLU pass trough a MaxPool2d\n",
        "    x = self.pool(F.relu(self.conv2(x)))  # twice\n",
        "    x = x.view(-1,16*5*5)  #\n",
        "    x = F.relu(self.fc1(x))  # F.relu = functional - use ReLU activation\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z1UxTeU4mfDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "id": "2PmzCDKPqfEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aecc077-0f8b-4aaa-beac-5779fff48ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The las tingredients we need are a loss function and an optimizer"
      ],
      "metadata": {
        "id": "oWokF-UBtSsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "AmjkBCoe1m6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss function is a measure of how far from our ideal output the model's prediction was.\n",
        "Cros-entropy loss is a typical loss function for classification models.\n",
        "\n",
        "The **optimizer** is what drives the learning. SGD optmizer, `lr`"
      ],
      "metadata": {
        "id": "8LNwltWh2Ed1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "\n",
        "for epoch in range(2):\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for i, data in enumerate(traindataloader, 0):\n",
        "    # get the inputs\n",
        "    inputs, labels = data\n",
        "\n",
        "    # zero the parameter gradient\n",
        "    optimizer.zero_grad() # gradient acumulates over batches\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    outputs = net(inputs)  # pass the data trhough the net\n",
        "    loss = loss_fn(outputs, labels)  # calculate the loss - get loss function\n",
        "    loss.backward()  # backpropagation\n",
        "    optimizer.step()  # adjust the optimizer\n",
        "\n",
        "    # print statistics\n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999: # print every 2000 mini-batches\n",
        "      print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss /2000))\n",
        "      running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "id": "t1yE9fl235AE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58784491-6fd9-4fe2-f5f1-9363daa03218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 2.202\n",
            "[1,  4000] loss: 1.864\n",
            "[1,  6000] loss: 1.677\n",
            "[1,  8000] loss: 1.614\n",
            "[1, 10000] loss: 1.544\n",
            "[1, 12000] loss: 1.498\n",
            "[2,  2000] loss: 1.429\n",
            "[2,  4000] loss: 1.405\n",
            "[2,  6000] loss: 1.371\n",
            "[2,  8000] loss: 1.342\n",
            "[2, 10000] loss: 1.312\n",
            "[2, 12000] loss: 1.277\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for data in tesdataloader:  # get the test set\n",
        "    images, labels = data  #get image and labels\n",
        "    outputs = net(images)  #get the predicitons\n",
        "    _, predicted = torch.max(outputs.data, 1)  #get the predicted tensor\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()  #compare the predicted with the ground truth, sum it and itemize\n",
        "\n",
        "print('Accuracy on the 10000 test images: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "id": "zC2_aVil6cV8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8864779-9217-486c-83f9-2d7374816268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the 10000 test images: 53 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to PyTorch Tensors\n",
        "\n",
        "Tensors are the central data abstraction in PyTorch."
      ],
      "metadata": {
        "id": "ShBBk5f8Fv0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math"
      ],
      "metadata": {
        "id": "IBuHIMYUyy6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Tensors\n",
        "\n",
        "`torch.empty()`"
      ],
      "metadata": {
        "id": "6xz00NLTy1lA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(3,4)\n",
        "print(type(x))\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voRNfWo1y8lK",
        "outputId": "ae4e08b2-094c-4040-9c2e-4c00e52d4671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[ 5.8516e-33,  0.0000e+00,  1.4013e-45,  0.0000e+00],\n",
            "        [ 1.0971e-36,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "        [ 5.2665e-33,  0.0000e+00, -1.4626e-26,  4.5562e-41]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's upack what we just did:\n",
        "\n",
        "* We builded a tensor using one of the numerous factory methods attached to the `torch` module\n",
        "* The tensor itself is 2-dimensional, having 3 rows and 4 columns\n",
        "* The type of the object returned is `torch.Tensor`, which is an alias for `torch.FloatTensor`; By default PyTorch tensors are 32-bit floating point\n",
        "* You will probabilly see some random-looking values when printing your tensor. The `torch.empty()` call allocates memory for the tensor, but not initialize it with any value.\n",
        "\n",
        "A brief note about tensors and their number of dimensions, and terminology:\n",
        "\n",
        "* You must sometimes see a 1-dimensional tensor called a *vector*\n",
        "* Likewise, a 2-dimensional tensor is often referred to a *matrix*\n",
        "* Anything with more than two dimensions is generally just called a *tensor*\n",
        "\n",
        "More often than not, you will want to initialize your tensor with some value."
      ],
      "metadata": {
        "id": "PYV86QpLzDD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = torch.zeros(2,3)\n",
        "print(zeros)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mId1dZTx33e-",
        "outputId": "bfd4a482-7c8c-4475-a75a-c22484981409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(3,4)\n",
        "print(ones)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnAPs72T38hd",
        "outputId": "d13cddb8-8ec1-4e94-8e80-42895a7c7708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1325)\n",
        "random = torch.rand(3,3)\n",
        "print(random)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh1-iZ_U4BXo",
        "outputId": "420c6ac6-dd08-4e64-fa82-47fdccddbb42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1847, 0.9887, 0.4666],\n",
            "        [0.4925, 0.6267, 0.5350],\n",
            "        [0.5099, 0.4483, 0.3611]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Tensors and Slicing\n",
        "\n",
        "`torch.manual_seeds()` assurance of reproducibility\n"
      ],
      "metadata": {
        "id": "PsDBiZwm4Hq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(125)\n",
        "random1 = torch.rand(3,4)\n",
        "print(random1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifntUHlB9k0o",
        "outputId": "f5653ef7-879d-46ea-d637-988154d75976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7219, 0.3854, 0.7279, 0.1047],\n",
            "        [0.6605, 0.7745, 0.9334, 0.6147],\n",
            "        [0.5578, 0.9899, 0.8673, 0.9288]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(125)\n",
        "random2 = torch.rand(3,4)\n",
        "print(random2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS1wIEfK9saO",
        "outputId": "20a4fea7-d80c-40e5-f198-e876961d1dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7219, 0.3854, 0.7279, 0.1047],\n",
            "        [0.6605, 0.7745, 0.9334, 0.6147],\n",
            "        [0.5578, 0.9899, 0.8673, 0.9288]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Shapes\n",
        "\n",
        "Often, when you are performing operations on two or more tensors, they will need to be of the same *shape* - that is, having the same number of dimensions and the same number of cells in each dimension. For that, we have the `torch.*_like()` methods:"
      ],
      "metadata": {
        "id": "0OGAxc5_91Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2,2,3)\n",
        "print(x.shape)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezvJkmCj-Xot",
        "outputId": "6c2fdac9-c0db-4cee-be91-b790f6ca781d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
            "\n",
            "        [[0.0000e+00, 0.0000e+00, 1.4013e-45],\n",
            "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty_like_x = torch.empty_like(x)\n",
        "print(empty_like_x.shape)\n",
        "print(empty_like_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f00kpXcB-i8N",
        "outputId": "a172c01c-5b3b-4f90-cf81-2c73d4cf06b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n",
            "tensor([[[-2.0735e+10,  4.5562e-41,  8.7042e-34],\n",
            "         [ 0.0000e+00,  5.8128e-34,  0.0000e+00]],\n",
            "\n",
            "        [[ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
            "         [ 0.0000e+00,  1.1734e-33,  0.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_like_x = torch.zeros_like(x)\n",
        "print(zeros_like_x.shape)\n",
        "print(zeros_like_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akPtELgi-ucs",
        "outputId": "6ce41b5d-20b2-4e45-ce40-c906b44dd5ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand_like_x = torch.rand_like(x)\n",
        "print(rand_like_x.shape)\n",
        "print(rand_like_x)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "ones_like_x = torch.ones_like(x)\n",
        "print(ones_like_x.shape)\n",
        "print(ones_like_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yRUMSLv_Rxm",
        "outputId": "c01c8ad4-196e-491d-eaf3-8e28da94c7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 3])\n",
            "tensor([[[0.7116, 0.5952, 0.6835],\n",
            "         [0.4139, 0.9702, 0.9073]],\n",
            "\n",
            "        [[0.9727, 0.4030, 0.0068],\n",
            "         [0.0175, 0.0490, 0.3330]]])\n",
            "\n",
            "\n",
            "torch.Size([2, 2, 3])\n",
            "tensor([[[1., 1., 1.],\n",
            "         [1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1.],\n",
            "         [1., 1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first new thing in the code and dell above is the use of `.shape` property in a tensor. This property contains a list of the extent of each dimension of a tensor.\n",
        "\n",
        "Below that, we call the `empty_like()`, `zeros_like()`, `ones_like()`, and `rand_like()`, them `.shape` method check if each one return a tensor with the same dimensions of the 1st one.\n",
        "\n",
        "The last way to build a tensor that will cover is to specify its data directly from a PyTorch collection:"
      ],
      "metadata": {
        "id": "unqgwHQU_tHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "some_constants = torch.tensor([[3.14159, 2.71828], [1.61803,0.0072897]])\n",
        "print(some_constants)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z7dIT_5Arwn",
        "outputId": "81fbdace-f45c-457c-bcfe-6833d5d821b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3.1416, 2.7183],\n",
            "        [1.6180, 0.0073]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "some_integers = torch.tensor((2,3,5,7,9,17,19))\n",
        "print(some_integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wELIbq_ABCz8",
        "outputId": "537b7759-ffae-474d-c0c8-73bd25b091d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2,  3,  5,  7,  9, 17, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "more_integers = torch.tensor(((2,4,6),[3,6,9]))\n",
        "print(more_integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MBUQhJOBQ16",
        "outputId": "09a9e626-6aea-47e0-a0d4-90530911fa43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2, 4, 6],\n",
            "        [3, 6, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Data Types\n",
        "\n",
        "Setting the datatype of a tensor is possible a couple of ways:\n"
      ],
      "metadata": {
        "id": "z13jY7BaBhhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones((2,3), dtype=torch.int16)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8n7UE5GBqea",
        "outputId": "2072dd30-ee11-4a91-bd40-d8ffb0cf8178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1]], dtype=torch.int16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.rand((2,3), dtype=torch.float64) * 20\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2YIReHNBzT_",
        "outputId": "e4231d95-8083-4328-c8cd-5d9cc1d8274d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13.4838, 15.3257, 14.1006],\n",
            "        [13.0557, 18.6816, 12.9664]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = b.to(torch.int32)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTtO92BHB-Uq",
        "outputId": "25485733-f214-4e06-c995-af58b3caee7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[13, 15, 14],\n",
            "        [13, 18, 12]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Math and Logic with PyTorch Tensors"
      ],
      "metadata": {
        "id": "uzuKB39ACHeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.zeros(2,2) + 1\n",
        "twos = torch.ones(2,2) * 2\n",
        "threes = (torch.ones(2,2) * 7 -1) / 2\n",
        "fours = twos ** 2\n",
        "sqrt2s = twos ** 0.5\n",
        "\n",
        "print(ones)\n",
        "print(\"\\n\")\n",
        "print(twos)\n",
        "print(\"\\n\")\n",
        "print(threes)\n",
        "print(\"\\n\")\n",
        "print(fours)\n",
        "print(\"\\n\")\n",
        "print(sqrt2s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DY3xJJRCk6q",
        "outputId": "742beb1b-4fd8-4cd2-93c1-5b00a5731f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "\n",
            "\n",
            "tensor([[2., 2.],\n",
            "        [2., 2.]])\n",
            "\n",
            "\n",
            "tensor([[3., 3.],\n",
            "        [3., 3.]])\n",
            "\n",
            "\n",
            "tensor([[4., 4.],\n",
            "        [4., 4.]])\n",
            "\n",
            "\n",
            "tensor([[1.4142, 1.4142],\n",
            "        [1.4142, 1.4142]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar operations between two tensor also behave like you would intuitively expect:"
      ],
      "metadata": {
        "id": "Ij6ADfbnDZk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "powers2 = twos ** torch.tensor([[1,2],[3,4]])\n",
        "print(powers2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLljXnXMDh5m",
        "outputId": "763a2238-0090-4c71-c915-53dcbbe3f890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2.,  4.],\n",
            "        [ 8., 16.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fives = ones + fours\n",
        "print(fives)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F551lLXcDq4O",
        "outputId": "d812088b-f00b-4aac-c523-f7a67e1aecaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5., 5.],\n",
            "        [5., 5.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dozens = threes * fours\n",
        "print(dozens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZGelqNYDybt",
        "outputId": "b4f329ea-5bf2-47e5-a56b-8209b8c574d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[12., 12.],\n",
            "        [12., 12.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In Brief: Tensor Boradcasting\n",
        "\n",
        "The exception to the same-shapes rule is *tensor broadcasting*.\n"
      ],
      "metadata": {
        "id": "QUkOoZZgESws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand = torch.rand(2,4)\n",
        "doubled = rand * (torch.ones(1,4) * 2)\n",
        "\n",
        "print(rand)\n",
        "print(doubled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtaI5XGsEk70",
        "outputId": "d46c57e7-a451-4dab-a98b-ae7d8fda9209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7034, 0.6243, 0.2870, 0.4096],\n",
            "        [0.3589, 0.8031, 0.3418, 0.8478]])\n",
            "tensor([[1.4069, 1.2486, 0.5740, 0.8192],\n",
            "        [0.7177, 1.6061, 0.6836, 1.6957]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rules for broadcasting are:\n",
        "\n",
        "* Each tensor must have at least one dimension - no empty tensors\n",
        "* Comparing the dimension sizs of the two tensors, *going from last o first*:\n",
        "  * Each dimension must be equal, *or*\n",
        "  * One of the dimensions must be of size 1, *or*\n",
        "  * The dimension does not exist in one of the tensors\n",
        "\n",
        "Tensors of identical shape, of course, are trivially \"broadcastable\""
      ],
      "metadata": {
        "id": "G1EkXEFTEw2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(4,3,2)\n",
        "\n",
        "b = a * torch.rand(3,2)  # 3rd and 2nd dims identical to a, dim 1 absent\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1atsGBVyIO9L",
        "outputId": "1aa478c8-e4d1-4ce1-8370-b3f7df59de1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.8821, 0.5835],\n",
            "         [0.4660, 0.5411],\n",
            "         [0.2206, 0.4123]],\n",
            "\n",
            "        [[0.8821, 0.5835],\n",
            "         [0.4660, 0.5411],\n",
            "         [0.2206, 0.4123]],\n",
            "\n",
            "        [[0.8821, 0.5835],\n",
            "         [0.4660, 0.5411],\n",
            "         [0.2206, 0.4123]],\n",
            "\n",
            "        [[0.8821, 0.5835],\n",
            "         [0.4660, 0.5411],\n",
            "         [0.2206, 0.4123]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = a * torch.rand(3,1)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7njF5xfIhUI",
        "outputId": "9233ee4d-16cf-4e90-f6d6-f1229adb47bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.9928, 0.9928],\n",
            "         [0.8846, 0.8846],\n",
            "         [0.8078, 0.8078]],\n",
            "\n",
            "        [[0.9928, 0.9928],\n",
            "         [0.8846, 0.8846],\n",
            "         [0.8078, 0.8078]],\n",
            "\n",
            "        [[0.9928, 0.9928],\n",
            "         [0.8846, 0.8846],\n",
            "         [0.8078, 0.8078]],\n",
            "\n",
            "        [[0.9928, 0.9928],\n",
            "         [0.8846, 0.8846],\n",
            "         [0.8078, 0.8078]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = a * torch.rand(1,2)\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSU8Yc5bIn6U",
        "outputId": "f7cb001d-e009-4987-fea5-3e06f6065744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.7427, 0.0572],\n",
            "         [0.7427, 0.0572],\n",
            "         [0.7427, 0.0572]],\n",
            "\n",
            "        [[0.7427, 0.0572],\n",
            "         [0.7427, 0.0572],\n",
            "         [0.7427, 0.0572]],\n",
            "\n",
            "        [[0.7427, 0.0572],\n",
            "         [0.7427, 0.0572],\n",
            "         [0.7427, 0.0572]],\n",
            "\n",
            "        [[0.7427, 0.0572],\n",
            "         [0.7427, 0.0572],\n",
            "         [0.7427, 0.0572]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look closely at the values of each tensor above:\n",
        "\n",
        "* The multiplication operation that built `b` was broadcaast over every \"layer\" of `a`\n",
        "* For `c`, the operation was broadcast over every layer and row of `a` -every 3-element column is identical.\n",
        "* For `d`, we switched it around - now every *row* is identical, across layers and columns\n",
        "\n",
        "## More Math with Tensors\n",
        "\n",
        "PyTorch tensors have over three hundred operations that can be performed on them"
      ],
      "metadata": {
        "id": "xfjxrWPfI651"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# common functions\n",
        "a = torch.rand(2,4) *2 - 1\n",
        "print(\"Common functions: \")\n",
        "print(torch.abs(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAVa0yc1KCio",
        "outputId": "2c076a6d-ea9e-4b3a-bfea-30c4b4a28ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common functions: \n",
            "tensor([[0.0077, 0.0504, 0.5100, 0.9995],\n",
            "        [0.9020, 0.0628, 0.4889, 0.3530]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.ceil(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTRT_QCHKbYf",
        "outputId": "3fe9063d-63f9-41e0-d5bd-ee885ecf57b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0., 1., -0., 1.],\n",
            "        [1., -0., -0., -0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.floor(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s4tuGZvKfiV",
        "outputId": "9e84dea9-b0ab-4ed8-e8e3-8ca836dbfd4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.,  0., -1.,  0.],\n",
            "        [ 0., -1., -1., -1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.clamp(a, -0.5, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b9hnd90Kipv",
        "outputId": "dcaa1a4e-e501-4f61-ca7b-bcfade7374ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0077,  0.0504, -0.5000,  0.5000],\n",
            "        [ 0.5000, -0.0628, -0.4889, -0.3530]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trigonometric functions and their inverses\n",
        "angles = torch.tensor([0, math.pi / 4, math.pi /2, 3 * math.pi /4])\n",
        "print(angles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHIJXmUmKpLk",
        "outputId": "8dcaaed4-ef2e-4461-f355-9428e4ff782f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sines = torch.sin(angles)\n",
        "print(sines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH23ytDGK5d9",
        "outputId": "b6be37a2-7245-4859-81e4-73a3e7fe3d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inverses = torch.asin(sines)\n",
        "print(inverses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJySC0fCLD1j",
        "outputId": "08bca09b-9bdf-429e-9826-a40cc50f6105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.7854, 1.5708, 0.7854])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bitwise operations\n",
        "print(\"\\nBitwise XOR: \")\n",
        "b = torch.tensor([1,5,11])\n",
        "c = torch.tensor([2,7,10])\n",
        "\n",
        "print(b)\n",
        "print(\"\\n\")\n",
        "print(c)\n",
        "print(\"\\n\")\n",
        "print(torch.bitwise_xor(b,c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWfCQKm1LLej",
        "outputId": "f74aecf7-49e1-4445-8d76-e734691dd9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bitwise XOR: \n",
            "tensor([ 1,  5, 11])\n",
            "\n",
            "\n",
            "tensor([ 2,  7, 10])\n",
            "\n",
            "\n",
            "tensor([3, 2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# comparisions\n",
        "d = torch.tensor([[1., 2.],[3.,4.]])\n",
        "e = torch.ones(1,2)\n",
        "print(torch.eq(d,e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5LpCL0hQWLy",
        "outputId": "d0cc9dde-afdb-472e-9e04-039c0d25e6cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ True, False],\n",
            "        [False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reductions\n",
        "print(torch.max(d))  # single element tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNDTMsPEQsuY",
        "outputId": "bc470670-d7bf-4ec0-a60a-8229c1dc5bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.max(d).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATDuRnNzRFqc",
        "outputId": "e2dc76d9-dfd2-4b1b-b919-9c37efa082f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.mean(d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v38e49XbRMO6",
        "outputId": "5a69538e-6b25-41e5-b480-730c438c6469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.std(d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGL9zZI4RPwc",
        "outputId": "82202c02-66b6-4c7c-d86f-29bcd87d2d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.2910)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.prod(d))  #product of all numbers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttLLcE10RUZz",
        "outputId": "d814396a-cd35-45ec-d748-30559c82f54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(24.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.unique(torch.tensor([1,2,1,2,1,2])))  # filter unique element"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWRCEWwjRbzf",
        "outputId": "841a90aa-98a2-4070-f3f8-5aefe9086ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vector and linear algebra operations\n",
        "v1 = torch.tensor([1.,0.,0.])\n",
        "v2 = torch.tensor([0.,1.,0.])\n",
        "m1 = torch.rand(2,2)\n",
        "m2 = torch.tensor([[3.,0.], [0.,3.]])\n",
        "\n",
        "print(torch.linalg.cross(v2, v1))  #negative of z unit vector (v1 x v2 == -v2 x v1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjoUJ2VLRn21",
        "outputId": "2381c4ee-44e5-4f60-8e13-1ab4d2a57eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.,  0., -1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(m1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9Gb7D_sSUV6",
        "outputId": "5c1ba57a-e52f-4eeb-efe9-9ca5816489bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2126, 0.4554],\n",
            "        [0.5411, 0.4905]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m3 = torch.linalg.matmul(m1,m2)\n",
        "print(m3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh81AHleSXQK",
        "outputId": "7cf9507e-7fec-4818-d277-2de0ced51346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6377, 1.3661],\n",
            "        [1.6234, 1.4714]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.linalg.svd(m3))  # singular value decompostion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVRakIXASdzD",
        "outputId": "e2649d63-4568-4aa3-d2fd-846d12b0078a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.return_types.linalg_svd(\n",
            "U=tensor([[-0.5553, -0.8316],\n",
            "        [-0.8316,  0.5553]]),\n",
            "S=tensor([2.6141, 0.4894]),\n",
            "Vh=tensor([[-0.6519, -0.7583],\n",
            "        [ 0.7583, -0.6519]]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Altering Tensors in Place\n",
        "\n",
        "Most binary operations on tensors will return a third new tensor. When we say `c = a * b`, the new tensor `c` will occupy a region of memory distinct from the other tensors.\n",
        "\n",
        "There are times, though, that you may wish to alter a tensor in place - for example, if you are doing an element-wise computation where you can discard intermediate values. For this, most of the math functions have a version with an appended underscore (`_`) that will alter a tensor in place."
      ],
      "metadata": {
        "id": "nR4UQw6TSqOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYLt1c-OUGhz",
        "outputId": "bbf94ee7-e55c-4598-ea51-d6822db7b369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.sin(a))  # this operation build a new tensor in memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9leaY8TUQ_Q",
        "outputId": "8f6b7111-98d4-4d48-ef0c-d3665c71ce4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)  # a has not changed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h8SAQm2UYe4",
        "outputId": "7c03cb54-c9ac-42d5-86d5-ad14cf61b1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr_C98hsUolo",
        "outputId": "fcdfeec7-701c-4776-b2f4-4a8642e6cbd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.7854, 1.5708, 2.3562])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.sin_(b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WSLhmGyUuiw",
        "outputId": "1513f75e-7bd2-469b-a931-4d30bcf5f4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b)  # b has changed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSGOi56AU0TG",
        "outputId": "ce72b091-1c46-4165-f8ae-3f240c08c866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0000, 0.7071, 1.0000, 0.7071])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For arithmetic operations, there are functions that behave similary:"
      ],
      "metadata": {
        "id": "eYCyH2p5U3oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(2, 2)\n",
        "b = torch.rand(2,2)\n",
        "\n",
        "print(a)\n",
        "print(\"\\n\")\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhrb6_RjVMc8",
        "outputId": "c4842f9b-ac11-4788-f2b1-775b26152bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "\n",
            "\n",
            "tensor([[0.9067, 0.5964],\n",
            "        [0.9480, 0.0323]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.add_(b))\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IReGh8nmVVT6",
        "outputId": "acf2238a-8c62-4ea8-d270-90d48adc6504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.9067, 1.5964],\n",
            "        [1.9480, 1.0323]])\n",
            "tensor([[1.9067, 1.5964],\n",
            "        [1.9480, 1.0323]])\n",
            "tensor([[0.9067, 0.5964],\n",
            "        [0.9480, 0.0323]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b.mul_(b))\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2UVTJGAVeQf",
        "outputId": "ce22e527-f7a7-4b9b-b8a2-007432ab6f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8221, 0.3557],\n",
            "        [0.8986, 0.0010]])\n",
            "tensor([[0.8221, 0.3557],\n",
            "        [0.8986, 0.0010]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(2,2)\n",
        "b = torch.rand(2,2)\n",
        "c = torch.zeros(2,2)\n",
        "\n",
        "old_id = id(c)  #"
      ],
      "metadata": {
        "id": "F0XYP7hbVx0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joCDWfo0V96f",
        "outputId": "c09388e3-11a2-4efe-9a2b-4532dd78abec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = torch.matmul(a,b, out=c)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfs6i6D-WA8O",
        "outputId": "83506504-76d3-413b-c5cf-21152724288e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0698, 1.1595],\n",
            "        [0.3429, 0.4001]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert c is d   # test c & d are the same object, not containing equal values\n",
        "assert id(c) == old_id  # make sure that our new c is the same object as the old one"
      ],
      "metadata": {
        "id": "7jU9_-bNVIPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(2,2, out=c)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzT-lkRZVYeK",
        "outputId": "989795bf-be82-4538-d104-40997c725b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4296, 0.3178],\n",
            "        [0.4992, 0.9284]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert id(c) == old_id  # still the same object\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBDI-abUVpuu",
        "outputId": "8a9be310-14cf-4eb6-f57c-3cf0e8ea1c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4296, 0.3178],\n",
            "        [0.4992, 0.9284]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copying Tensors\n",
        "\n",
        "As with any object in Python, assigning a tensor to a varible makes the variable a *label* of the tensor, and does not copy it. For example:"
      ],
      "metadata": {
        "id": "uRneWS0JV2A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(2,2)\n",
        "b = a"
      ],
      "metadata": {
        "id": "XwA53IlkWPrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a[0][1] = 561\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3xRjXPmWUEq",
        "outputId": "8ccb0af3-7b1c-4de8-c5bc-072eefa84f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  1., 561.],\n",
            "        [  1.,   1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But what if you want a separate copy of the data to work on? The `clone` method should be used:"
      ],
      "metadata": {
        "id": "ObKAj9OQWbo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(3,3)\n",
        "b = a.clone()\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejFiyKhrWl_a",
        "outputId": "67e2731a-bbb2-471a-a06e-d2061f7d5159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert b is not a   # different objects in memory\n",
        "print(torch.eq(a,b))   # but still with the same contents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghnUoE5bW2k5",
        "outputId": "b0870ddd-a8e2-464e-b655-573cb22db53f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[True, True, True],\n",
            "        [True, True, True],\n",
            "        [True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[0][1] = 258\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpwN9yH_XDaI",
        "outputId": "88f3e35d-9072-4193-e681-a096b82690f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There is an important thing to be aware of when using `clone()`**. If your source tensor has autograd, enabled then so will the clone. **This will be covered more deeply in the video on autograd**.\n",
        "\n",
        "If your model has multiple computation paths in its `forward()` method, and *both* the original tensor and its clone contribute to the model's output, then to enable model learning you want autograd turned on for both tensors."
      ],
      "metadata": {
        "id": "EbKRDiBxXQKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.rand(3,3, requires_grad=True)  # turn on autograd\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mxuCZJbZ3yQ",
        "outputId": "bfa20977-1354-4f35-a3de-a0950b9ea810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9296, 0.5939, 0.1371],\n",
            "        [0.1972, 0.1117, 0.9535],\n",
            "        [0.2096, 0.8589, 0.7376]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = a.clone()\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYGu99i3aBdV",
        "outputId": "650fb236-56a4-4f49-ea11-434d4f8ccc6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9296, 0.5939, 0.1371],\n",
            "        [0.1972, 0.1117, 0.9535],\n",
            "        [0.2096, 0.8589, 0.7376]], grad_fn=<CloneBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = a.detach().clone()\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G_CO9nJaGHU",
        "outputId": "c2e4ab43-f2da-4490-e2c8-045ed56865f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9296, 0.5939, 0.1371],\n",
            "        [0.1972, 0.1117, 0.9535],\n",
            "        [0.2096, 0.8589, 0.7376]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC9ses8HaNgY",
        "outputId": "bea1ba77-bfc5-41af-8497-55c825ca9402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9296, 0.5939, 0.1371],\n",
            "        [0.1972, 0.1117, 0.9535],\n",
            "        [0.2096, 0.8589, 0.7376]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving to Accelerator\n",
        "\n",
        "One the major advanteges of PyTorch is its robust acceleration on an **accelerator** such as CUDA, MPS, MTIA, or XPU. How to move to faster hardware?\n",
        "\n",
        "First check whether an accelerator is available, with the `is_available()` method."
      ],
      "metadata": {
        "id": "lMF79_huaWRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.accelerator.is_available():\n",
        "  print(\"We have an accelerator\")\n",
        "else:\n",
        "  print(\"Only CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONTy9cx6bI7O",
        "outputId": "5e82e777-3fef-46d3-bf9b-63fd03a61b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Must put the data in someplace where the accelerator can see it. In CPU the data is in computer's RAM. The accelerator has attached memory to it. To performa a computation on a device, *all* the data must be moved  for that memory access to the computation on the device. **Moving the data to memory accessible by the accelerator**"
      ],
      "metadata": {
        "id": "5r85_6dhbbMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.accelerator.is_available():\n",
        "  gpu_rand = torch.rand(2,2, device=torch.accelerator.current_accelerator())\n",
        "  print(gpu_rand)\n",
        "else:\n",
        "  print(\"Only CPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ-o7q2Kb___",
        "outputId": "9ce6ce99-b62d-432c-918a-013ba277fa00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "the_device = torch.accelerator.current_accelerator() if torch.accelerator.is_available() else torch.device('cpu')\n",
        "print(\"Device: {}\".format(the_device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sr8sy0J6cp7l",
        "outputId": "789be4c1-7625-4d87-fc7f-fe5cac6edbab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2, device=the_device)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8R_0g-Ac-r4",
        "outputId": "061f5edf-45c2-400a-fb6b-2ad8e1b665ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9392, 0.6402],\n",
            "        [0.0835, 0.8189]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to know that in order to do computation involving two or more tensors, *all of the tensors must be on the same device**."
      ],
      "metadata": {
        "id": "IlsoOJg4dFr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3,3)\n",
        "y = torch.rand(3,3) #, device = 'cuda')\n",
        "z = x + y\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orR6PTJmda4d",
        "outputId": "36746231-e836-44cd-ba58-28b86f2b2c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.5766, 0.6797, 0.6494],\n",
            "        [0.4924, 1.4856, 0.9668],\n",
            "        [1.0417, 1.1170, 0.9398]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manipulating Tensor Shape\n",
        "\n",
        "Some time is needed to change the shape of your tensor\n",
        "\n",
        "### Changing the Number of Dimensions\n",
        "\n",
        "One case you might need to change the number of dimensions is passing a single instance of input to your model.\n",
        "\n",
        "image = 3 x 226 x 226 -> tensor of shape: `3,226,226` -The model is expecting input of shape `N, 3, 226, 266` - `N` is the batch number images"
      ],
      "metadata": {
        "id": "ghlgqSvDdO6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = torch.rand(3,226,226)\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip2Nfv9xh2mh",
        "outputId": "f5c277a3-1f76-43a7-9621-365cae4aadd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.3204, 0.8058, 0.0370,  ..., 0.2195, 0.2207, 0.7330],\n",
            "         [0.8361, 0.3658, 0.6938,  ..., 0.9683, 0.3638, 0.2475],\n",
            "         [0.5820, 0.2608, 0.6153,  ..., 0.7359, 0.8985, 0.1118],\n",
            "         ...,\n",
            "         [0.9496, 0.4388, 0.8936,  ..., 0.9678, 0.8317, 0.6429],\n",
            "         [0.7641, 0.8809, 0.3937,  ..., 0.0847, 0.8107, 0.8816],\n",
            "         [0.0609, 0.1981, 0.9407,  ..., 0.3599, 0.3107, 0.7289]],\n",
            "\n",
            "        [[0.6043, 0.4600, 0.4547,  ..., 0.4690, 0.1008, 0.1081],\n",
            "         [0.3463, 0.8656, 0.7683,  ..., 0.0406, 0.0699, 0.1389],\n",
            "         [0.6053, 0.2353, 0.8936,  ..., 0.3387, 0.4694, 0.7640],\n",
            "         ...,\n",
            "         [0.6626, 0.5311, 0.5382,  ..., 0.9648, 0.0547, 0.2062],\n",
            "         [0.5867, 0.5908, 0.7050,  ..., 0.8685, 0.2570, 0.2347],\n",
            "         [0.0152, 0.3167, 0.4279,  ..., 0.7190, 0.9231, 0.6000]],\n",
            "\n",
            "        [[0.6983, 0.9499, 0.7530,  ..., 0.4081, 0.7838, 0.8676],\n",
            "         [0.9744, 0.2991, 0.6545,  ..., 0.6733, 0.6091, 0.5449],\n",
            "         [0.8270, 0.8316, 0.7049,  ..., 0.0496, 0.9466, 0.8584],\n",
            "         ...,\n",
            "         [0.1821, 0.6942, 0.9091,  ..., 0.2420, 0.2845, 0.7362],\n",
            "         [0.8993, 0.0794, 0.1101,  ..., 0.2872, 0.9523, 0.3352],\n",
            "         [0.7001, 0.2248, 0.7227,  ..., 0.4015, 0.8091, 0.5525]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = d.unsqueeze(0)\n",
        "\n",
        "print(d.shape)\n",
        "print(e.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmlNOZrzhKMM",
        "outputId": "3683e8bd-61fe-46fc-ee2c-cc13efe30672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 226, 226])\n",
            "torch.Size([1, 3, 226, 226])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `unsqueeze()` method adds a dimension of extent 1. `unsqueeze(0) adds it as a new zeroth dimension - now you have a batch of one.\n",
        "\n",
        "So if that's *uns*queezing? What do we mean by squeezing? We are taking advantage of the fact that any dimension of extent 1 *does not* change the number of elements in the tensor."
      ],
      "metadata": {
        "id": "5dxpTRdqiYCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = torch.rand(1,1,1,1,1)\n",
        "print(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni7MuOVyjKH3",
        "outputId": "16ca8733-2312-4c3b-ef9a-7ff8d5a22fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[[0.6776]]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.rand(1,20)\n",
        "print(g.shape)\n",
        "print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvdjhGsgjjw3",
        "outputId": "f383407b-9065-4920-b8d3-7bb971e11019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 20])\n",
            "tensor([[0.8323, 0.2391, 0.2215, 0.4867, 0.6418, 0.4243, 0.4272, 0.3588, 0.3616,\n",
            "         0.0756, 0.7566, 0.7580, 0.5265, 0.0769, 0.3226, 0.2676, 0.1703, 0.0250,\n",
            "         0.1297, 0.1785]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = g.squeeze(0)\n",
        "print(h.shape)\n",
        "print(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DPhOvfpjp-_",
        "outputId": "fcaaec4d-3cce-4fcd-b63d-e4e86697fbf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20])\n",
            "tensor([0.8323, 0.2391, 0.2215, 0.4867, 0.6418, 0.4243, 0.4272, 0.3588, 0.3616,\n",
            "        0.0756, 0.7566, 0.7580, 0.5265, 0.0769, 0.3226, 0.2676, 0.1703, 0.0250,\n",
            "        0.1297, 0.1785])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = torch.rand(2,2)\n",
        "print(i.shape)\n",
        "print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ9m8uZaj5uu",
        "outputId": "d106b998-5b20-45c1-8823-980e9ef086ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "tensor([[0.9845, 0.7858],\n",
            "        [0.0054, 0.8430]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "j = i.squeeze(0)\n",
        "print(j.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c79tMi8j-m_",
        "outputId": "07d10991-73d6-4402-b5ed-eadd738eb7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may only `squeeze()` dimensions of extend 1.\n",
        "\n",
        "Calls to `squeeze()` and `unsqueeze()` can only act on dimensions of extent 1 because to do otherwise would change the number of elements in the tensor."
      ],
      "metadata": {
        "id": "oQMhWZDgkQyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.ones(4,3,2)\n",
        "print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATRCdETvlOHb",
        "outputId": "32dbaaa4-e998-4685-dfe8-0f49ece1762f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = k * torch.rand(3,1)\n",
        "print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TklnRqElVfP",
        "outputId": "be88ee90-a58f-4da2-d31d-03339a22543c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.1269, 0.1269],\n",
            "         [0.0603, 0.0603],\n",
            "         [0.5838, 0.5838]],\n",
            "\n",
            "        [[0.1269, 0.1269],\n",
            "         [0.0603, 0.0603],\n",
            "         [0.5838, 0.5838]],\n",
            "\n",
            "        [[0.1269, 0.1269],\n",
            "         [0.0603, 0.0603],\n",
            "         [0.5838, 0.5838]],\n",
            "\n",
            "        [[0.1269, 0.1269],\n",
            "         [0.0603, 0.0603],\n",
            "         [0.5838, 0.5838]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.ones(4,3,2)\n",
        "n = torch.rand(3)\n",
        "o = n.unsqueeze(1)\n",
        "\n",
        "print(m)\n",
        "print(n)\n",
        "print(o)\n",
        "print(o.shape)\n",
        "print(m * o)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnDdqaHZljxe",
        "outputId": "da38dbe8-c1ac-429d-cc4f-681a3ebf19d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]]])\n",
            "tensor([0.5477, 0.1734, 0.5365])\n",
            "tensor([[0.5477],\n",
            "        [0.1734],\n",
            "        [0.5365]])\n",
            "torch.Size([3, 1])\n",
            "tensor([[[0.5477, 0.5477],\n",
            "         [0.1734, 0.1734],\n",
            "         [0.5365, 0.5365]],\n",
            "\n",
            "        [[0.5477, 0.5477],\n",
            "         [0.1734, 0.1734],\n",
            "         [0.5365, 0.5365]],\n",
            "\n",
            "        [[0.5477, 0.5477],\n",
            "         [0.1734, 0.1734],\n",
            "         [0.5365, 0.5365]],\n",
            "\n",
            "        [[0.5477, 0.5477],\n",
            "         [0.1734, 0.1734],\n",
            "         [0.5365, 0.5365]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `squeeze()` and `unsqueeze()` methods also hevwe in-place versions `squeeze_()` and `unsqueeze_()`"
      ],
      "metadata": {
        "id": "OI0OS826mBv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_me = torch.rand(3,226,226)\n",
        "print(batch_me.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22nIy9dBmQPO",
        "outputId": "cd194dbf-ae94-401a-8bca-b7be8d62a43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 226, 226])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_me.unsqueeze_(0)\n",
        "print(batch_me.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfJsH2fzmY5W",
        "outputId": "5d54d7a5-7279-4c29-db88-357627824c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 226, 226])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the shape of a tensor more radically, while still preserving the number of elements and their contents. One case whre this happens is at the interface between a convolutional layer of a model and a linear layer of the model - this is common in image classification models. A convolutional kernel will yield an output tensor of shape *features x width x height*, but the following layer expects a 1-dimensional input. `reshape()` will do this for you, provided tha the dimensions you request yield the same number of elements as the input tensor has."
      ],
      "metadata": {
        "id": "lT0LlKxEnpnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output3d = torch.rand(6,20,20)\n",
        "print(output3d.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fps7LDP0pbU9",
        "outputId": "773e7f59-2a1f-4628-9fea-f8f3d8049a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 20, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input1d = output3d.reshape( 6 * 20 * 20)\n",
        "print(input1d.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c0EJ8d9piG1",
        "outputId": "54cfb63c-b6eb-4534-de4d-fe63a9cc6a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can also call it as a method on the torhc module\n",
        "print(torch.reshape(output3d, (6*20*20,)).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raSGNn-cpugV",
        "outputId": "99fdc709-d8ae-4b1b-af6e-d40a06dfd220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2400])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NumPy Bridge\n"
      ],
      "metadata": {
        "id": "23P8PYTFqed2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "numpy_array = np.ones((2,3))\n",
        "print(numpy_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jBQZzIFqqq1",
        "outputId": "9fe797f7-2fa0-402a-8d72-866f9d742105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_tensor = torch.from_numpy(numpy_array)\n",
        "print(pytorch_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH8ZnkI9q0yh",
        "outputId": "9ff6af42-39c5-4a46-d56b-a55495d17c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand_pytorch = torch.rand(3,4)\n",
        "print(rand_pytorch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuM8NDQnrHyl",
        "outputId": "d442bee0-5fb4-4438-a1f5-1afabcff8f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3954, 0.0095, 0.8254, 0.8930],\n",
            "        [0.1860, 0.0600, 0.3284, 0.9694],\n",
            "        [0.8756, 0.2252, 0.5117, 0.7928]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand_numpy = rand_pytorch.numpy()\n",
        "print(rand_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3kcaVPtrN9N",
        "outputId": "cf5c471a-86ce-4d6e-a63c-ae6513358dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.39537996 0.00950062 0.82537323 0.8929838 ]\n",
            " [0.18599337 0.06004375 0.32843876 0.9694138 ]\n",
            " [0.87563914 0.22523832 0.5117328  0.7928024 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to know that these converted objects are using *the same underlying memory* as their source objects, meaning that changes to one are reflected in the other."
      ],
      "metadata": {
        "id": "HxctDSJ4rZm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_array[1,1] = 23\n",
        "print(pytorch_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRc7Q9VKrojN",
        "outputId": "2ebfc1b2-5b73-42c9-bfea-7c7143cf4565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  1.,  1.],\n",
            "        [ 1., 23.,  1.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand_pytorch[1,1] = 18\n",
        "print(rand_numpy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1E333hOruWv",
        "outputId": "6298f9ee-9307-4704-f460-631005221109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.9537996e-01 9.5006227e-03 8.2537323e-01 8.9298379e-01]\n",
            " [1.8599337e-01 1.8000000e+01 3.2843876e-01 9.6941382e-01]\n",
            " [8.7563914e-01 2.2523832e-01 5.1173282e-01 7.9280239e-01]]\n"
          ]
        }
      ]
    }
  ]
}